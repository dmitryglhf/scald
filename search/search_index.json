{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Scald","text":"<p>Scalable Collaborative Agents for Data Science</p> <p>Scald automates machine learning workflows using collaborative AI agents and the Model Context Protocol. Unlike traditional AutoML frameworks that rely on exhaustive search or rigid pipelines, Scald employs two specialized agents\u2014Actor and Critic\u2014that iteratively refine solutions through feedback loops.</p>"},{"location":"#core-approach","title":"Core Approach","text":"<p>The Actor agent analyzes data, engineers features, and trains models using six specialized MCP servers as tools. The Critic agent evaluates each solution and provides targeted feedback. Through iterative refinement (typically 5 cycles), this collaboration produces optimized models while learning from past experiences via ChromaDB-based memory.</p> <p>Scald supports classification and regression tasks using gradient boosting algorithms (CatBoost, LightGBM, XGBoost), with automatic EDA, preprocessing, and hyperparameter tuning.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from scald import Scald\n\nscald = Scald(max_iterations=5)\npredictions = await scald.run(\n    train_path=\"train.csv\",\n    test_path=\"test.csv\",\n    target=\"price\",\n    task_type=\"regression\"\n)\n</code></pre>"},{"location":"#why-scald","title":"Why Scald?","text":"<p>Traditional AutoML performs exhaustive grid searches or follows predefined strategies. Scald's agents reason about data characteristics, adapt strategies dynamically, and transfer knowledge between tasks. This results in higher quality solutions with fewer wasted iterations and transparent, interpretable decision-making throughout the process.</p>"},{"location":"#architecture","title":"Architecture","text":"<p>The system orchestrates Actor-Critic loops with workspace isolation, comprehensive logging, and cost tracking. Each session produces artifacts, predictions, and detailed execution logs for full reproducibility.</p>"},{"location":"#navigation","title":"Navigation","text":"<ul> <li>Installation - Setup in minutes</li> <li>Quick Start - First AutoML task</li> <li>Architecture - System design</li> <li>Actor-Critic Pattern - Agent collaboration</li> <li>MCP Servers - Available tools</li> </ul>"},{"location":"actor-critic/","title":"Actor-Critic Pattern","text":"<p>Scald implements collaborative problem-solving through two specialized agents with complementary roles: the Actor proposes solutions while the Critic evaluates and guides refinement.</p>"},{"location":"actor-critic/#actor-the-solver","title":"Actor: The Solver","text":"<p>The Actor is an LLM-powered data scientist with access to six MCP servers. Each iteration begins by reviewing the Critic's previous feedback, then analyzing data characteristics to inform strategy. The Actor makes decisions about encoding methods, scaling approaches, feature engineering, and algorithm selection based on data properties rather than fixed rules.</p> <p>Using MCP servers as tools, the Actor performs exploratory analysis, applies transformations, trains gradient boosting models (CatBoost, LightGBM, or XGBoost), and generates predictions. All work produces executable code saved as artifacts, ensuring reproducibility. The Actor leverages past experiences from memory to inform decisions about preprocessing and modeling strategies.</p>"},{"location":"actor-critic/#critic-the-reviewer","title":"Critic: The Reviewer","text":"<p>The Critic evaluates solutions without access to MCP servers, ensuring objective review based on code quality and methodology rather than direct data manipulation. Each evaluation examines preprocessing appropriateness, algorithm suitability for the task, potential issues or edge cases, and overall solution quality.</p> <p>The Critic provides specific, actionable feedback rather than generic observations. Feedback might identify unhandled missing values, suggest feature engineering opportunities, recommend algorithm adjustments, or point out logical errors. Based on evaluation, the Critic either accepts the solution for the next iteration or requests specific improvements.</p>"},{"location":"actor-critic/#iteration-dynamics","title":"Iteration Dynamics","text":"<p>The first iteration starts with the Actor analyzing data and creating an initial solution. The Critic reviews this baseline and provides targeted feedback. In subsequent iterations, the Actor incorporates feedback progressively, addressing issues while maintaining what worked. Each cycle refines the approach through specific adjustments rather than complete rebuilds.</p> <p>Convergence occurs when the Critic accepts the solution with high confidence, performance plateaus across iterations, or maximum iterations are reached. Typically, 5 iterations provide good balance between quality and cost.</p>"},{"location":"actor-critic/#example-feedback-evolution","title":"Example Feedback Evolution","text":"<p>Iteration 1: \"F1 score of 0.72 shows promise, but categorical features lack encoding and missing values in 'age' remain unhandled. Apply one-hot encoding and imputation in the next iteration.\"</p> <p>Iteration 3: \"Improvement to F1 0.84 with solid preprocessing. Consider extracting temporal features from 'date' column and exploring interaction terms between 'age' and 'income'. Current solution is acceptable but refinable.\"</p> <p>Iteration 5: \"Excellent F1 of 0.89 with comprehensive feature engineering, proper encoding, and well-tuned hyperparameters. Solution is production-ready.\"</p>"},{"location":"actor-critic/#memory-integration","title":"Memory Integration","text":"<p>Both agents benefit from ChromaDB-based long-term memory. The Actor retrieves preprocessing strategies, feature engineering patterns, and algorithm choices from similar past tasks. The Critic recalls common pitfalls, quality standards, and evaluation criteria relevant to the task type. This enables transfer learning across problems and faster convergence on novel datasets.</p>"},{"location":"actor-critic/#benefits","title":"Benefits","text":"<p>Separating solving from reviewing reduces errors through independent evaluation. Iterative refinement with targeted feedback produces higher quality outcomes than single-pass approaches. Natural language feedback provides interpretable insight into decision-making. Memory-based transfer learning reduces wasted iterations on similar problems.</p>"},{"location":"actor-critic/#configuration","title":"Configuration","text":"<p>Control the refinement process through iteration count:</p> <pre><code>scald = Scald(max_iterations=5)  # Default balance\n</code></pre> <p>Increase for complex tasks requiring more refinement; decrease for simple problems or faster prototyping.</p> <p>Continue to MCP Servers to understand the Actor's toolkit.</p>"},{"location":"api/","title":"API Reference","text":"<p>Complete reference for Scald classes and methods.</p>"},{"location":"api/#scald","title":"Scald","text":"<p>Main orchestrator for AutoML workflows.</p> <p>Main orchestrator for Actor-Critic ML automation.</p>"},{"location":"api/#scald.Scald.run","title":"run  <code>async</code>","text":"<pre><code>run(\n    train_path: str | Path,\n    test_path: str | Path,\n    target: str,\n    task_type: TaskType,\n) -&gt; np.ndarray\n</code></pre> <p>Execute Actor-Critic loop with long-term memory.</p>"},{"location":"api/#usage","title":"Usage","text":"<pre><code>import asyncio\nfrom scald import Scald\n\nasync def main():\n    scald = Scald(max_iterations=5)\n\n    predictions = await scald.run(\n        train_path=\"train.csv\",\n        test_path=\"test.csv\",\n        target=\"price\",\n        task_type=\"regression\"\n    )\n\n    return predictions\n\nresults = asyncio.run(main())\n</code></pre>"},{"location":"api/#type-signatures","title":"Type Signatures","text":"<pre><code>from typing import List\n\nclass Scald:\n    def __init__(self, max_iterations: int = 5) -&gt; None: ...\n\n    async def run(\n        self,\n        train_path: str,\n        test_path: str,\n        target: str,\n        task_type: str\n    ) -&gt; List[float | int | str]: ...\n</code></pre>"},{"location":"api/#return-values","title":"Return Values","text":"<p><code>run()</code> returns predictions as a list. For classification, list contains class labels (int or str). For regression, list contains numeric predictions (float). List length matches test data row count.</p>"},{"location":"api/#exceptions","title":"Exceptions","text":"<p>Common exceptions: <code>FileNotFoundError</code> for missing data files, <code>ValueError</code> for invalid task_type or missing target column, <code>RuntimeError</code> for API or execution failures.</p> <p>Error handling:</p> <pre><code>try:\n    predictions = await scald.run(...)\nexcept FileNotFoundError:\n    print(\"Data file missing\")\nexcept ValueError:\n    print(\"Invalid parameters\")\nexcept Exception as e:\n    print(f\"Error: {e}\")\n</code></pre> <p>See Python API Guide for practical examples and Configuration for settings.</p>"},{"location":"architecture/","title":"Architecture","text":"<p>Scald orchestrates collaborative AI agents, MCP servers, and a learning system to automate machine learning workflows.</p>"},{"location":"architecture/#core-components","title":"Core Components","text":"<p>Scald Orchestrator manages the Actor-Critic loop, tracking iterations, costs, and performance metrics. It handles workspace isolation, session management, and artifact preservation. Each run creates an independent session with dedicated logging and storage.</p> <p>Actor Agent is an LLM-powered data scientist that explores data, engineers features, and trains models. It has access to six MCP servers providing data operations, statistical analysis, preprocessing, model training, file management, and structured reasoning. The Actor generates executable code for each pipeline stage, storing artifacts for reproducibility.</p> <p>Critic Agent evaluates Actor solutions without access to MCP servers. This separation ensures objective review based on code quality and reasoning rather than direct data manipulation. The Critic provides targeted feedback, identifies issues, and decides whether to accept solutions or request refinement.</p> <p>Memory Manager uses ChromaDB with Jina embeddings to store and retrieve past experiences. When facing a new task, the system queries memory for similar problems, retrieving relevant preprocessing strategies, feature engineering patterns, and algorithm choices. This enables transfer learning across datasets.</p> <p>MCP Servers provide specialized capabilities: data-preview for inspection, data-analysis for statistics and correlations, data-processing for transformations, machine-learning for model training, file-operations for I/O, and sequential-thinking for complex reasoning decomposition.</p>"},{"location":"architecture/#workflow","title":"Workflow","text":"<p>Initialization creates an isolated workspace and session directory. The system retrieves relevant experiences from memory based on task characteristics. The Actor-Critic loop then executes for the specified number of iterations.</p> <p>Within each iteration, the Actor reviews previous feedback (if any), analyzes data characteristics, designs preprocessing strategy, trains models, and submits the solution. The Critic evaluates code quality, methodology, and performance, providing specific feedback for improvement. This continues until convergence or maximum iterations.</p> <p>After the loop completes, the best solution is selected, applied to test data for final predictions, and all artifacts are saved with comprehensive logging and cost reports.</p>"},{"location":"architecture/#data-flow","title":"Data Flow","text":"<p>Training and test CSV files flow to the Actor, which applies preprocessing, trains a model, and produces artifacts. The Critic reviews these artifacts and provides feedback, which influences the next iteration. The final model generates predictions saved to CSV.</p>"},{"location":"architecture/#session-management","title":"Session Management","text":"<p>Each execution creates a timestamped directory:</p> <pre><code>sessions/session_YYYYMMDD_HHMMSS/\n\u251c\u2500\u2500 session.log          # Execution logs\n\u251c\u2500\u2500 artifacts/           # Code per iteration\n\u2514\u2500\u2500 predictions.csv      # Final output\n</code></pre> <p>Sessions are independent and can run concurrently without interference.</p>"},{"location":"architecture/#scalability","title":"Scalability","text":"<p>Workspace isolation prevents conflicts between concurrent runs. Agents operate statelessly, requiring explicit context passing. ChromaDB efficiently handles large experience databases. Built-in cost tracking monitors API usage per session, enabling budget control.</p> <p>Continue to Actor-Critic Pattern for deeper understanding of agent collaboration.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<p>Python 3.11+, uv package manager, and an OpenRouter API key (or compatible LLM provider).</p>"},{"location":"installation/#setup","title":"Setup","text":"<p>Install uv if needed:</p> <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre> <p>Clone and install Scald:</p> <pre><code>git clone https://github.com/yourusername/scald.git\ncd scald\nuv sync\n</code></pre>"},{"location":"installation/#configuration","title":"Configuration","text":"<p>Copy the environment template and add your API credentials:</p> <pre><code>cp .env.example .env\n</code></pre> <p>Edit <code>.env</code>:</p> <pre><code>OPENROUTER_API_KEY=your_api_key_here\nOPENROUTER_BASE_URL=https://openrouter.ai/api/v1\n</code></pre>"},{"location":"installation/#verification","title":"Verification","text":"<p>Confirm installation:</p> <pre><code>scald --help\n</code></pre> <p>You should see the CLI help output with available commands and options.</p>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>For documentation:</p> <pre><code>uv sync --group docs\nmkdocs serve  # Available at http://localhost:8000\n</code></pre> <p>For development:</p> <pre><code>uv sync --group dev\n</code></pre> <p>Continue to Quick Start to run your first AutoML task.</p>"},{"location":"mcp-servers/","title":"MCP Servers","text":"<p>Scald uses the Model Context Protocol to provide specialized tools to the Actor agent. Each server exposes domain-specific operations for data science tasks.</p>"},{"location":"mcp-servers/#available-servers","title":"Available Servers","text":"<p>data-preview enables quick inspection of data structure, column types, dimensions, and sample rows. The Actor uses this for initial exploration and schema verification.</p> <p>data-analysis performs statistical computations including descriptive statistics, correlation matrices, distribution analysis, missing value detection, and outlier identification. This supports exploratory data analysis and pattern discovery.</p> <p>data-processing handles transformations: categorical encoding (one-hot, label, target), feature scaling (standard, minmax, robust), missing value imputation, and feature engineering (polynomial features, interactions). The Actor builds preprocessing pipelines using these operations.</p> <p>machine-learning provides model training with CatBoost, LightGBM, and XGBoost. It includes hyperparameter tuning via Optuna, cross-validation, performance evaluation using task-appropriate metrics (accuracy, F1, RMSE, R\u00b2), and prediction generation.</p> <p>file-operations manages I/O for CSV data, Python code artifacts, serialized models, and intermediate results. This enables data loading, artifact persistence, and prediction export.</p> <p>sequential-thinking supports structured problem decomposition and multi-step reasoning. The Actor uses this for complex workflows requiring careful planning across multiple operations.</p>"},{"location":"mcp-servers/#server-architecture","title":"Server Architecture","text":"<p>Each MCP server runs in isolation, communicating via the standard protocol. The Actor selects appropriate tools based on current task needs, while the Critic has no server access to maintain evaluation objectivity.</p>"},{"location":"mcp-servers/#typical-usage-pattern","title":"Typical Usage Pattern","text":"<p>Actor workflows generally follow this sequence: preview data structure, analyze statistics and patterns, process features and clean data, train models with machine-learning server, and save artifacts via file-operations. The sequential-thinking server supports complex reasoning throughout.</p>"},{"location":"mcp-servers/#server-benefits","title":"Server Benefits","text":"<p>Modularity keeps responsibilities clear and components independently testable. Servers provide validated interfaces with error handling and resource limits for safe execution. The standard MCP protocol enables reusability across different agents and projects. Extending Scald requires only implementing new MCP servers with defined tool interfaces.</p>"},{"location":"mcp-servers/#limitations","title":"Limitations","text":"<p>Only the Actor accesses MCP servers\u2014the Critic reviews without tools to ensure objective evaluation. Servers operate statelessly, requiring explicit context in each call. This design enforces clear boundaries and prevents hidden dependencies.</p> <p>Continue to CLI Usage for command-line interface reference or Python API for programmatic usage.</p>"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#prepare-data","title":"Prepare Data","text":"<p>Scald expects CSV files with training data (features + target) and test data (same features). The target column should be numeric for regression or categorical for classification.</p> <pre><code>feature_1,feature_2,target\n1.2,3.4,0\n2.3,4.5,1\n</code></pre>"},{"location":"quickstart/#cli-usage","title":"CLI Usage","text":"<p>Run AutoML with a single command:</p> <pre><code>scald --train data/train.csv \\\n      --test data/test.csv \\\n      --target price \\\n      --task-type regression \\\n      --max-iterations 5\n</code></pre> <p>Task type must be either <code>classification</code> or <code>regression</code>. Iterations control Actor-Critic refinement cycles (default: 5).</p>"},{"location":"quickstart/#python-api","title":"Python API","text":"<p>For programmatic control:</p> <pre><code>import asyncio\nfrom scald import Scald\n\nasync def main():\n    scald = Scald(max_iterations=5)\n\n    predictions = await scald.run(\n        train_path=\"data/train.csv\",\n        test_path=\"data/test.csv\",\n        target=\"target_column\",\n        task_type=\"classification\"\n    )\n\n    print(f\"Generated {len(predictions)} predictions\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"quickstart/#execution-flow","title":"Execution Flow","text":"<p>The workflow progresses through data preview, exploratory analysis, preprocessing, model training, and evaluation. The Critic reviews each iteration and provides feedback. The Actor refines the approach based on this feedback, converging on an optimal solution. Each iteration improves upon the previous attempt through targeted adjustments.</p>"},{"location":"quickstart/#output","title":"Output","text":"<p>Scald creates a timestamped session directory containing detailed logs, generated code artifacts, and final predictions:</p> <pre><code>sessions/session_20250113_143022/\n\u251c\u2500\u2500 session.log          # Execution logs\n\u251c\u2500\u2500 artifacts/           # Generated code per iteration\n\u2514\u2500\u2500 predictions.csv      # Final predictions\n</code></pre> <p>Console output shows iteration progress, final metrics, cost, and execution time.</p>"},{"location":"quickstart/#troubleshooting","title":"Troubleshooting","text":"<p>API key errors indicate missing or incorrect credentials in <code>.env</code>. Memory errors suggest insufficient RAM for the dataset size. Poor performance can be improved by increasing <code>max_iterations</code> for additional refinement cycles.</p> <p>Continue to Architecture to understand how Scald works internally.</p>"},{"location":"usage/api/","title":"Python API","text":"<p>Use Scald programmatically for full control over AutoML workflows.</p>"},{"location":"usage/api/#basic-usage","title":"Basic Usage","text":"<pre><code>import asyncio\nfrom scald import Scald\n\nasync def main():\n    scald = Scald(max_iterations=5)\n\n    predictions = await scald.run(\n        train_path=\"data/train.csv\",\n        test_path=\"data/test.csv\",\n        target=\"target_column\",\n        task_type=\"classification\"\n    )\n\n    print(f\"Generated {len(predictions)} predictions\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"usage/api/#api-reference","title":"API Reference","text":"<p><code>Scald(max_iterations=5)</code> creates an instance. The parameter controls Actor-Critic refinement cycles.</p> <p><code>await scald.run(train_path, test_path, target, task_type)</code> executes the AutoML workflow. Returns a list of predictions matching test data rows. Task type must be \"classification\" or \"regression\".</p>"},{"location":"usage/api/#examples","title":"Examples","text":"<p>Classification:</p> <pre><code>async def classify():\n    scald = Scald(max_iterations=5)\n    predictions = await scald.run(\n        train_path=\"customers_train.csv\",\n        test_path=\"customers_test.csv\",\n        target=\"will_purchase\",\n        task_type=\"classification\"\n    )\n    return predictions\n\nresults = asyncio.run(classify())\n</code></pre> <p>Regression:</p> <pre><code>async def predict_prices():\n    scald = Scald(max_iterations=3)\n    predictions = await scald.run(\n        train_path=\"housing_train.csv\",\n        test_path=\"housing_test.csv\",\n        target=\"sale_price\",\n        task_type=\"regression\"\n    )\n    return predictions\n\nresults = asyncio.run(predict_prices())\n</code></pre>"},{"location":"usage/api/#return-values","title":"Return Values","text":"<p>The <code>run()</code> method returns predictions as a list. For classification, elements are class labels (int or str). For regression, elements are numeric values (float). Length matches the number of test data rows.</p>"},{"location":"usage/api/#error-handling","title":"Error Handling","text":"<pre><code>try:\n    predictions = await scald.run(...)\nexcept FileNotFoundError:\n    print(\"Data file missing\")\nexcept ValueError:\n    print(\"Invalid parameters\")\nexcept Exception as e:\n    print(f\"Execution error: {e}\")\n</code></pre>"},{"location":"usage/api/#batch-processing","title":"Batch Processing","text":"<p>Process multiple datasets sequentially:</p> <pre><code>async def process_batch(datasets):\n    scald = Scald(max_iterations=5)\n    results = {}\n\n    for name, config in datasets.items():\n        predictions = await scald.run(**config)\n        results[name] = predictions\n\n    return results\n\ndatasets = {\n    \"housing\": {\n        \"train_path\": \"housing_train.csv\",\n        \"test_path\": \"housing_test.csv\",\n        \"target\": \"price\",\n        \"task_type\": \"regression\"\n    },\n    \"churn\": {\n        \"train_path\": \"churn_train.csv\",\n        \"test_path\": \"churn_test.csv\",\n        \"target\": \"churned\",\n        \"task_type\": \"classification\"\n    }\n}\n\nresults = asyncio.run(process_batch(datasets))\n</code></pre>"},{"location":"usage/api/#async-context","title":"Async Context","text":"<p>Scald uses async/await for non-blocking execution. Always use <code>await</code> with <code>run()</code> or wrap in <code>asyncio.run()</code> for top-level calls.</p> <p>Continue to Configuration for advanced settings.</p>"},{"location":"usage/cli/","title":"CLI Usage","text":"<p>Run Scald from the command line for straightforward AutoML tasks.</p>"},{"location":"usage/cli/#basic-command","title":"Basic Command","text":"<pre><code>scald --train &lt;train.csv&gt; --test &lt;test.csv&gt; --target &lt;column&gt; --task-type &lt;type&gt;\n</code></pre> <p>All four parameters are required. Task type must be either <code>classification</code> or <code>regression</code>.</p>"},{"location":"usage/cli/#options","title":"Options","text":"<p><code>--train</code> specifies the training CSV file path. <code>--test</code> specifies the test CSV file path. <code>--target</code> names the target column in training data. <code>--task-type</code> defines the problem type. <code>--max-iterations</code> controls refinement cycles (default: 5).</p>"},{"location":"usage/cli/#examples","title":"Examples","text":"<p>Classification:</p> <pre><code>scald --train data/titanic_train.csv \\\n      --test data/titanic_test.csv \\\n      --target survived \\\n      --task-type classification \\\n      --max-iterations 5\n</code></pre> <p>Regression:</p> <pre><code>scald --train data/housing_train.csv \\\n      --test data/housing_test.csv \\\n      --target price \\\n      --task-type regression\n</code></pre>"},{"location":"usage/cli/#output","title":"Output","text":"<p>Scald creates a session directory with logs, artifacts, and predictions:</p> <pre><code>sessions/session_20250113_143022/\n\u251c\u2500\u2500 session.log\n\u251c\u2500\u2500 artifacts/\n\u2514\u2500\u2500 predictions.csv\n</code></pre> <p>Console output shows iteration progress, final metrics, cost, and execution time.</p>"},{"location":"usage/cli/#configuration","title":"Configuration","text":"<p>Ensure <code>.env</code> contains API credentials:</p> <pre><code>OPENROUTER_API_KEY=your_api_key\nOPENROUTER_BASE_URL=https://openrouter.ai/api/v1\n</code></pre>"},{"location":"usage/cli/#help","title":"Help","text":"<p>View all options:</p> <pre><code>scald --help\n</code></pre>"},{"location":"usage/cli/#troubleshooting","title":"Troubleshooting","text":"<p>\"API key not found\" indicates missing <code>OPENROUTER_API_KEY</code> in <code>.env</code>. \"File not found\" means incorrect CSV paths. \"Invalid task type\" requires using <code>classification</code> or <code>regression</code>.</p> <p>Continue to Python API for programmatic usage.</p>"},{"location":"usage/configuration/","title":"Configuration","text":"<p>Control Scald behavior through environment variables and initialization parameters.</p>"},{"location":"usage/configuration/#environment-variables","title":"Environment Variables","text":"<p>Configure API access in <code>.env</code>:</p> <pre><code># API credentials (required)\nOPENROUTER_API_KEY=your_api_key\nOPENROUTER_BASE_URL=https://openrouter.ai/api/v1\n\n# Model selection (optional)\nMODEL_NAME=anthropic/claude-3.5-sonnet\n\n# Logging verbosity (optional)\nLOG_LEVEL=INFO\n</code></pre> <p>Model name depends on your API provider. OpenRouter supports many LLMs. Log level options: DEBUG, INFO, WARNING, ERROR.</p>"},{"location":"usage/configuration/#initialization-parameters","title":"Initialization Parameters","text":"<p><code>max_iterations</code> controls Actor-Critic refinement cycles:</p> <pre><code>scald = Scald(max_iterations=10)\n</code></pre> <p>Higher values increase solution quality and cost. Lower values reduce both. Default of 5 balances quality and efficiency.</p> <p>Recommendations: Use 3 for simple tasks, 5 for standard problems, 7-10 for complex datasets.</p>"},{"location":"usage/configuration/#runtime-parameters","title":"Runtime Parameters","text":"<p><code>task_type</code> specifies classification or regression. Classification handles binary or multiclass problems with discrete labels, using accuracy, F1, precision, and recall metrics. Regression predicts continuous numeric values, using RMSE, MAE, and R\u00b2 metrics.</p>"},{"location":"usage/configuration/#data-requirements","title":"Data Requirements","text":"<p>Training and test CSV files must share the same feature columns. The target column must exist in training data and may optionally appear in test data. Both files should use standard CSV format with headers.</p>"},{"location":"usage/configuration/#session-management","title":"Session Management","text":"<p>Sessions automatically create timestamped directories in <code>./sessions</code>. Each contains execution logs, generated artifacts, and predictions. Sessions run independently and support concurrent execution without conflicts.</p>"},{"location":"usage/configuration/#memory-storage","title":"Memory Storage","text":"<p>ChromaDB stores long-term memory in <code>.chroma/</code> directory. Default settings typically work well. The memory system accumulates experiences across sessions, enabling transfer learning.</p>"},{"location":"usage/configuration/#cost-optimization","title":"Cost Optimization","text":"<p>Reduce API costs by lowering <code>max_iterations</code>, using cheaper models (configured in <code>.env</code>), or working with smaller datasets during prototyping. Scald tracks token usage and costs per session in logs.</p>"},{"location":"usage/configuration/#performance-tuning","title":"Performance Tuning","text":"<p>For faster execution, use <code>max_iterations=3</code>, smaller training sets, or simpler models. For higher quality, increase iterations to 7+, provide more training data, or allow more refinement cycles.</p> <p>Large datasets require sufficient RAM. Consider sampling for initial exploration, then scaling to full data for final training.</p>"},{"location":"usage/configuration/#custom-models","title":"Custom Models","text":"<p>Use different LLM providers by editing <code>.env</code>:</p> <pre><code>MODEL_NAME=local/llama-3\nOPENROUTER_BASE_URL=http://localhost:8000/v1\nOPENROUTER_API_KEY=dummy\n</code></pre>"},{"location":"usage/configuration/#example-configurations","title":"Example Configurations","text":"<p>Development (fast, cheap):</p> <pre><code># .env: MODEL_NAME=anthropic/claude-3-haiku, LOG_LEVEL=DEBUG\nscald = Scald(max_iterations=3)\n</code></pre> <p>Production (high quality):</p> <pre><code># .env: MODEL_NAME=anthropic/claude-3.5-sonnet, LOG_LEVEL=INFO\nscald = Scald(max_iterations=7)\n</code></pre> <p>Standard (balanced):</p> <pre><code># .env: MODEL_NAME=anthropic/claude-3.5-sonnet, LOG_LEVEL=INFO\nscald = Scald(max_iterations=5)  # Default\n</code></pre> <p>Continue to API Reference for detailed class documentation.</p>"}]}